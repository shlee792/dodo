{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk를 불러오고 os는 외부에서 파일을 불러올 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'a man in the house' # untokenized string\n",
    "t = ['a', 'man', 'in', 'the', 'house'] # tokenized seqeuence of words as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.Text로 nltk 전용 variable로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nltk.Text(t)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t와 s.split은 같은 값이므로 a와 b도 같은 값을 가짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nltk.Text(s.split())\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getcwd는 os 에서 현재 디렉토리를 받아오는 함수. 06_01.txt는 현재 utf8로 인코딩되어있는 텍스트. read로 불러옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = open(os.getcwd()+r'/06_01.txt', encoding = 'utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw[:200]은 200까지만 불러오기. 이때 200개란 알파벳 하나 단위이며 space까지 포함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "1154507\n",
      "The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky\n",
      "\n",
      "This eBook is for the use of anyone anywhere at no cost and with\n",
      "almost no restrictions whatsoever.  You may copy it, give it\n"
     ]
    }
   ],
   "source": [
    "print(type(raw))\n",
    "print(len(raw))\n",
    "print(raw[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk에 포함된 word-tokenize라는 함수는 split과 같은 역할. 이때 len(tokens)은 단어의 개수를 의미.\n",
    "nltk속에 있는 다양한 함수를 사용하기 위해 nltk.Text로 nltk 전용 variable으로의 변환이 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "257726\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(raw)\n",
    "print(type(tokens))\n",
    "print(len(tokens))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fftth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text.collocations는 텍스트에서 pair로 자주 나오는 단어들의 조합을 파악할 수 있는 함수. 이러한 함수를 사용하기 위해 같은 형태라도 list를 nltk.Text 해 줄 필요가 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.text.Text'>\n",
      "['The', 'Project', 'Gutenberg', 'EBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']\n",
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Ilya Petrovitch; Project\n",
      "Gutenberg; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text = nltk.Text(tokens)\n",
    "print(type(text))\n",
    "print(text[:10])\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concordance 함수로 great라는 단어를 중심으로 양쪽으로 총 79개의 문자를 찾는데 아래로 25개의 great가 나열 될때 까지 찾을 수 있음. 이를 통해 great라는 단어들이 각각 어떤 문맥 속에서 사용되는지 알수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 162 matches:\n",
      "and were more frequent in periods of great strain . In 1859 he was allowed to r\n",
      "ndency and of late she had read with great interest a book she got through Mr. \n",
      " the bosom of her family ... . And a great deal more ... . Quite excusable , si\n",
      "that you had heard that Dounia had a great deal to put up with in the Svidrigra\n",
      "g will she has . Dounia can endure a great deal and even in the most difficult \n",
      " that letter she reproached him with great heat and indignation for the basenes\n",
      "putation ; they had seen and known a great deal more than Mr. Svidrigailov had \n",
      "n other people ’ s . In my opinion a great deal , a very great deal of all this\n",
      " In my opinion a great deal , a very great deal of all this was unnecessary ; b\n",
      " . He is a very busy man and is in a great hurry to get to Petersburg , so that\n",
      " me that , though he is not a man of great education , he is clever and seems t\n",
      " very well . Of course , there is no great love either on his side , or on hers\n",
      "tted the matter has been arranged in great haste . Besides he is a man of great\n",
      "great haste . Besides he is a man of great prudence and he will see , to be sur\n",
      "d that she is ready to put up with a great deal , if only their future relation\n",
      " off for Petersburg , where he has a great deal of business , and he wants to o\n",
      "a or I breathed a word to him of the great hopes we have of his helping us to p\n",
      "ites that ‘ Dounia can put up with a great deal. ’ I know that very well . I kn\n",
      "at , that ‘ Dounia can put up with a great deal. ’ If she could put up with Mr.\n",
      "it , she certainly can put up with a great deal . And now mother and she have t\n",
      "e young , and she was walking in the great heat bareheaded and with no parasol \n",
      "f the skirt , close to the waist : a great piece was rent and hanging loose . A\n",
      "ts or conversations . He worked with great intensity without sparing himself , \n",
      " uproarious and was reputed to be of great physical strength . One night , when\n",
      ". His legs felt suddenly heavy and a great drowsiness came upon him . He turned\n"
     ]
    }
   ],
   "source": [
    "text.concordance('great', 79, 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\fftth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ch.isalpha를 이용하여 ch가 알파벳이면 lowercase해서 list로 만드는 for루프. 이때 for루프가 char와 count 두 개의 정보를 가지고 5번 반복하는데 char요소만 받아옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['e', 't', 'a', 'o', 'n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "# fdist = nltk.FreqDist(raw)\n",
    "# print(fdist.most_common(50))\n",
    "\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "print(fdist.most_common(5))\n",
    "[char for (char, count) in fdist.most_common(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zymosis',\n",
       " 'zymosterol',\n",
       " 'zymosthenic',\n",
       " 'zymotechnic',\n",
       " 'zymotechnical',\n",
       " 'zymotechnics',\n",
       " 'zymotechny',\n",
       " 'zymotic',\n",
       " 'zymotically',\n",
       " 'zymotize',\n",
       " 'zymotoxic',\n",
       " 'zymurgy',\n",
       " 'Zyrenian',\n",
       " 'Zyrian',\n",
       " 'Zyryan',\n",
       " 'zythem',\n",
       " 'Zythia',\n",
       " 'zythum',\n",
       " 'Zyzomys']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.words.words('en')[-20:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.words.words('en'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
