{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\\n.\\t        Wildcard, matches any character\\n^abc\\t    Matches some pattern abc at the start of a string\\nabc$\\t    Matches some pattern abc at the end of a string\\n[abc]\\t    Matches one of a set of characters\\n[^abc]      Matches anything but a set of characters\\n[A-Z0-9]\\tMatches one of a range of characters\\ned|ing|s\\tMatches one of the specified strings (disjunction)\\n*\\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\\n+\\t        One or more of previous item, e.g. a+, [a-z]+\\n?\\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\\n{n}\\t        Exactly n repeats where n is a non-negative integer\\n{n,}\\t    At least n repeats\\n{,n}\\t    No more than n repeats\\n{m,n}\\t    At least m and no more than n repeats\\na(b|c)+\\t    Parentheses that indicate the scope of the operators\\n(...)       Matches whatever regular expression is inside the parentheses\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
    ".\t        Wildcard, matches any character\n",
    "^abc\t    Matches some pattern abc at the start of a string\n",
    "abc$\t    Matches some pattern abc at the end of a string\n",
    "[abc]\t    Matches one of a set of characters\n",
    "[^abc]      Matches anything but a set of characters\n",
    "[A-Z0-9]\tMatches one of a range of characters\n",
    "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
    "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
    "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
    "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
    "{n}\t        Exactly n repeats where n is a non-negative integer\n",
    "{n,}\t    At least n repeats\n",
    "{,n}\t    No more than n repeats\n",
    "{m,n}\t    At least m and no more than n repeats\n",
    "a(b|c)+\t    Parentheses that indicate the scope of the operators\n",
    "(...)       Matches whatever regular expression is inside the parentheses\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aal', 'aalii', 'aam', 'aardvark', 'aardwolf', 'aba', 'abac', 'abaca']\n",
      "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n",
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector']\n",
      "['gold', 'golf', 'hold', 'hole']\n",
      "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']\n",
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5']\n",
      "['C$', 'US$']\n",
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934']\n",
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point']\n",
      "['black-and-white', 'bread-and-butter', 'father-in-law', 'machine-gun-toting', 'savings-and-loan']\n",
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]\n",
    "print(wordlist[:10])\n",
    "result = [w for w in wordlist if re.search('ed$', w)][:10]\n",
    "print(result[:10])\n",
    "result = [w for w in wordlist if re.search('^..j..t..$', w)][:10]\n",
    "print(result[:10])\n",
    "result = [w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)][:10]\n",
    "print(result[:10])\n",
    "result = [w for w in wordlist if re.search('^[ah]+$', w)][:10]\n",
    "print(result[:10])\n",
    "\n",
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "wordlist = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
    "print(wordlist[:10])\n",
    "wordlist = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
    "print(wordlist[:10])\n",
    "wordlist = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
    "print(wordlist[:10])\n",
    "wordlist = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
    "print(wordlist[:10])\n",
    "wordlist = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
    "print(wordlist[:10])\n",
    "wordlist = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']\n",
      "['rc', 'fr', 'st', 'xp', 'ci']\n",
      "['supercalifragilisticexpialidocious']\n",
      "['sup', 'rcal', 'frag', 'lis', 'tic', 'xpial', 'doc']\n"
     ]
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "result = re.findall('[aeiou]', word)\n",
    "print(result)\n",
    "result = re.findall('[aeiou](..)[aeiou]', word)\n",
    "print(result)\n",
    "result = re.findall('[^aeiou].+[^aeiou]', word) # greedy search\n",
    "print(result)\n",
    "result = re.findall('[^aeiou].+?[^aeiou]', word) # reluctant search\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('io', 549),\n",
       " ('ea', 476),\n",
       " ('ie', 331),\n",
       " ('ou', 329),\n",
       " ('ai', 261),\n",
       " ('ia', 253),\n",
       " ('ee', 217),\n",
       " ('oo', 174),\n",
       " ('ua', 109),\n",
       " ('au', 106)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(vs for word in wsj for vs in re.findall('[aeiou]{2,}', word))\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('62%-owned', 1),\n",
       " ('Absorbed', 1),\n",
       " ('According', 1),\n",
       " ('Adopting', 1),\n",
       " ('Advanced', 1),\n",
       " ('Advancing', 1),\n",
       " ('Alfred', 1),\n",
       " ('Allied', 1),\n",
       " ('Annualized', 1),\n",
       " ('Anything', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(wordlist)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 위에서 wordlist 대신에 '사전'을 입력하면 most_common(10)의 모든 변수는 1의 값을 가짐. 왜냐하면 사전에는 서로 다른 단어가 한번 씩만 등장하기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to\n",
      "[nltk_data]     C:\\Users\\fftth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\udhr.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('udhr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Universal', 'Declaration', 'of', 'Human', 'Rights', ...]\n"
     ]
    }
   ],
   "source": [
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(english_udhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수를 만들 때는 def(define)을 이용해서 함수를 입력하고 괄호안에 입력값을 넣음. 입력값이 다수 일 때는 comma를 이용. 함수의 내용 부분은 tab이든 space든 정해진 길이 만큼은 띄어줘야 함.\n",
    "return은 함수의 출력값을 의미. return을 입력하지 않으면 내부적 연산만 할 뿐 출력을 하지 않음.\n",
    ".join은 list들을 \"안에서 정의하는 glue를 이용하여 붙이는 것. 만약 ' '인 경우 한칸의 space를 간격으로 두고 붙이게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unvrsl',\n",
       " 'Dclrtn',\n",
       " 'of',\n",
       " 'Hmn',\n",
       " 'Rghts',\n",
       " 'Prmble',\n",
       " 'Whrs',\n",
       " 'rcgntn',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inhrnt',\n",
       " 'dgnty',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'eql',\n",
       " 'and',\n",
       " 'inlnble',\n",
       " 'rghts',\n",
       " 'of',\n",
       " 'all',\n",
       " 'mmbrs',\n",
       " 'of',\n",
       " 'the',\n",
       " 'hmn',\n",
       " 'fmly',\n",
       " 'is',\n",
       " 'the',\n",
       " 'fndtn',\n",
       " 'of',\n",
       " 'frdm',\n",
       " ',',\n",
       " 'jstce',\n",
       " 'and',\n",
       " 'pce',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wrld',\n",
       " ',',\n",
       " 'Whrs',\n",
       " 'dsrgrd',\n",
       " 'and',\n",
       " 'cntmpt',\n",
       " 'fr',\n",
       " 'hmn',\n",
       " 'rghts',\n",
       " 'hve',\n",
       " 'rsltd',\n",
       " 'in',\n",
       " 'brbrs',\n",
       " 'acts',\n",
       " 'whch',\n",
       " 'hve',\n",
       " 'outrgd',\n",
       " 'the',\n",
       " 'cnscnce',\n",
       " 'of',\n",
       " 'mnknd',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'advnt',\n",
       " 'of',\n",
       " 'a',\n",
       " 'wrld',\n",
       " 'in',\n",
       " 'whch',\n",
       " 'hmn',\n",
       " 'bngs',\n",
       " 'shll',\n",
       " 'enjy',\n",
       " 'frdm',\n",
       " 'of',\n",
       " 'spch',\n",
       " 'and']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp = '^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "[compress(w) for w in english_udhr[:75]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package toolbox to\n",
      "[nltk_data]     C:\\Users\\fftth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\toolbox.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('toolbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [cv for w in rotokas_words for cv in re.findall('[ptksvr][aeiou]', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConditionalFreqDist는 list가 반드시 2개짜리여야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(cvs) # CFD works pairwise only\n",
    "cfd.tabulate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
